{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-09T18:04:20.967744Z",
     "start_time": "2025-06-09T18:02:44.195402Z"
    }
   },
   "source": [
    "from scipy.cluster.vq import vq\n",
    "import numpy as np\n",
    "import glob\n",
    "from skimage.feature import SIFT\n",
    "import cv2\n",
    "from PIL.Image import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "bishop_path = glob.glob(\"bishop_resized/*.jpg\", recursive=True)\n",
    "knight_path = glob.glob(\"knight-resize/*.jpg\", recursive=True)\n",
    "pawn_path = glob.glob(\"pawn_resized/*.jpg\", recursive=True)\n",
    "queen_path = glob.glob(\"Queen-resized/*.jpg\", recursive=True)\n",
    "rook_path = glob.glob(\"Rook-resize/*.jpg\", recursive=True)\n",
    "\n",
    "image_paths = bishop_path + knight_path + pawn_path + queen_path + rook_path\n",
    "\n",
    "images = [cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) for image_path in image_paths]\n",
    "\n",
    "sift = SIFT()\n",
    "descriptors = []\n",
    "\n",
    "images_valid = []\n",
    "descriptors = []\n",
    "\n",
    "for img in images:\n",
    "    try:\n",
    "        sift.detect_and_extract(img)\n",
    "        if sift.descriptors is not None and len(sift.descriptors) > 0:\n",
    "            descriptors.append(sift.descriptors)\n",
    "            images_valid.append(img)  # Î¼ÏŒÎ½Î¿ Ï„Î¹Ï‚ Ï‡ÏÎ®ÏƒÎ¹Î¼ÎµÏ‚\n",
    "    except RuntimeError:\n",
    "        print(\"SIFT failed on one image. Skipping.\")\n",
    "\n",
    "images_gray = [cv2.imread(p, cv2.IMREAD_GRAYSCALE) for p in image_paths]\n",
    "\n",
    "image_paths_valid = []\n",
    "for img, path in zip(images_gray, image_paths):\n",
    "    for valid_img in images_valid:\n",
    "        if np.array_equal(img, valid_img):\n",
    "            image_paths_valid.append(path)\n",
    "            break\n",
    "\n",
    "all_descriptors = np.vstack([desc for desc in descriptors if desc is not None]).astype(float)\n",
    "\n",
    "# -------------------- 4. Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· KMeans (Î»ÎµÎ¾Î¹ÎºÏŒ) --------------------\n",
    "k = 100  # Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ visual words\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "attempts = 10\n",
    "flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "\n",
    "all_descriptors = all_descriptors.astype(np.float32)\n",
    "\n",
    "compactness, labels, centers = cv2.kmeans(all_descriptors, k, None, criteria, attempts, flags)\n",
    "codebook = centers\n",
    "\n",
    "# -------------------- 5. Î‘Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· descriptors ÏƒÎµ visual words --------------------\n",
    "visual_words = []\n",
    "for desc in descriptors:\n",
    "    if desc is not None:\n",
    "        words, _ = vq(desc, codebook)\n",
    "    else:\n",
    "        words = np.array([])\n",
    "    visual_words.append(words)\n",
    "\n",
    "# -------------------- 6. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± BoVW vector (Î¹ÏƒÏ„ÏŒÎ³ÏÎ±Î¼Î¼Î±) --------------------\n",
    "bovw_vectors = []\n",
    "for words in visual_words:\n",
    "    hist = np.zeros(k)\n",
    "    for w in words:\n",
    "        hist[w] += 1\n",
    "    bovw_vectors.append(hist)\n",
    "\n",
    "bovw_vectors = np.stack(bovw_vectors)\n",
    "\n",
    "# -------------------- 7. (Î ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬) TF-IDF Î¼ÎµÏ„Î±ÏƒÏ‡Î·Î¼Î±Ï„Î¹ÏƒÎ¼ÏŒÏ‚ --------------------\n",
    "N = len(bovw_vectors)\n",
    "df = np.sum(bovw_vectors > 0, axis=0)\n",
    "idf = np.log(N / (df + 1e-6))  # Î¼Î¹ÎºÏÎ® Ï„Î¹Î¼Î® Î³Î¹Î± Î±Ï€Î¿Ï†Ï…Î³Î® log(0)\n",
    "tf_idf = bovw_vectors * idf\n",
    "\n",
    "# -------------------- 8. Î ÏÎ¿Î²Î¿Î»Î® Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ --------------------\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT failed on one image. Skipping.\n",
      "SIFT failed on one image. Skipping.\n",
      "SIFT failed on one image. Skipping.\n",
      "SIFT failed on one image. Skipping.\n",
      "SIFT failed on one image. Skipping.\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T18:04:21.032306Z",
     "start_time": "2025-06-09T18:04:21.006478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "# B\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "import os\n",
    "\n",
    "query_filenames = [\n",
    "    \"Queen-Resized/00000000_resized.jpg\",\n",
    "    \"Queen-Resized/00000001_resized.jpg\",\n",
    "    \"Rook-resize/00000001_resized.jpg\",\n",
    "    \"Rook-resize/00000002_resized.jpg\",\n",
    "    \"bishop_resized/00000000_resized.jpg\",\n",
    "    \"bishop_resized/00000002_resized.jpg\",\n",
    "    \"knight-resize/00000001_resized.jpg\",\n",
    "    \"knight-resize/00000002_resized.jpg\",\n",
    "    \"pawn_resized/00000001_resized.jpg\",\n",
    "    \"pawn_resized/00000002_resized.jpg\"\n",
    "]\n",
    "\n",
    "# Î‘Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· path -> index\n",
    "image_path_map = {os.path.normpath(p): i for i, p in enumerate(image_paths_valid)}\n",
    "\n",
    "# Î›Î¯ÏƒÏ„Î± Î¼Îµ index Ï„Ï‰Î½ query ÎµÎ¹ÎºÏŒÎ½Ï‰Î½\n",
    "query_indices = []\n",
    "for q in query_filenames:\n",
    "    q_norm = os.path.normpath(q)\n",
    "    if q_norm in image_path_map:\n",
    "        query_indices.append(image_path_map[q_norm])\n",
    "    else:\n",
    "        print(f\"âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ: {q}\")\n",
    "\n",
    "\n",
    "features = tf_idf  # Î¼Ï€Î¿ÏÎµÎ¯Ï‚ ÎºÎ±Î¹ bovw_vectors Î±Î½ Î´ÎµÎ½ Î¸Î­Î»ÎµÎ¹Ï‚ TF-IDF\n",
    "dist_matrix = cdist(features, features, metric='euclidean')\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for query_idx in query_indices:\n",
    "    dists = dist_matrix[query_idx]\n",
    "    dists[query_idx] = np.inf  # Î±Î³Î½Î¿Î¿ÏÎ¼Îµ Ï„Î·Î½ Î¯Î´Î¹Î± Ï„Î·Î½ ÎµÎ¹ÎºÏŒÎ½Î±\n",
    "\n",
    "    top_indices = np.argsort(dists)[:10]\n",
    "\n",
    "    query_label = image_paths_valid[query_idx].split(os.sep)[0].lower()\n",
    "    retrieved_labels = [image_paths_valid[i].split(os.sep)[0].lower() for i in top_indices]\n",
    "\n",
    "    correct = sum(1 for lbl in retrieved_labels if lbl == query_label)\n",
    "    accuracy = correct / 10.0\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Query: {query_label} | Accuracy: {accuracy:.2f} | Retrieved: {retrieved_labels}\")\n",
    "\n",
    "# ÎœÎ­ÏƒÎ· Î±ÎºÏÎ¯Î²ÎµÎ¹Î±\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(f\"\\nğŸ“Š ÎœÎ­ÏƒÎ· Î‘ÎºÏÎ¯Î²ÎµÎ¹Î± Î‘Î½Î¬ÎºÏ„Î·ÏƒÎ·Ï‚ (Top-10): {mean_accuracy:.2f}\")"
   ],
   "id": "f71aceae73df8f96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ: Queen-Resized/00000000_resized.jpg\n",
      "âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ: Queen-Resized/00000001_resized.jpg\n",
      "Query: rook-resize | Accuracy: 0.10 | Retrieved: ['knight-resize', 'bishop_resized', 'bishop_resized', 'pawn_resized', 'pawn_resized', 'knight-resize', 'pawn_resized', 'knight-resize', 'pawn_resized', 'rook-resize']\n",
      "Query: rook-resize | Accuracy: 0.40 | Retrieved: ['pawn_resized', 'pawn_resized', 'knight-resize', 'bishop_resized', 'bishop_resized', 'pawn_resized', 'rook-resize', 'rook-resize', 'rook-resize', 'rook-resize']\n",
      "Query: bishop_resized | Accuracy: 0.20 | Retrieved: ['bishop_resized', 'pawn_resized', 'rook-resize', 'rook-resize', 'bishop_resized', 'rook-resize', 'rook-resize', 'knight-resize', 'knight-resize', 'pawn_resized']\n",
      "Query: bishop_resized | Accuracy: 0.40 | Retrieved: ['bishop_resized', 'pawn_resized', 'rook-resize', 'bishop_resized', 'bishop_resized', 'pawn_resized', 'rook-resize', 'pawn_resized', 'rook-resize', 'bishop_resized']\n",
      "Query: knight-resize | Accuracy: 0.20 | Retrieved: ['rook-resize', 'knight-resize', 'bishop_resized', 'bishop_resized', 'rook-resize', 'knight-resize', 'bishop_resized', 'bishop_resized', 'rook-resize', 'rook-resize']\n",
      "Query: knight-resize | Accuracy: 0.30 | Retrieved: ['pawn_resized', 'pawn_resized', 'knight-resize', 'pawn_resized', 'bishop_resized', 'bishop_resized', 'knight-resize', 'knight-resize', 'pawn_resized', 'bishop_resized']\n",
      "Query: pawn_resized | Accuracy: 0.00 | Retrieved: ['knight-resize', 'knight-resize', 'bishop_resized', 'rook-resize', 'bishop_resized', 'rook-resize', 'bishop_resized', 'rook-resize', 'knight-resize', 'bishop_resized']\n",
      "Query: pawn_resized | Accuracy: 0.40 | Retrieved: ['bishop_resized', 'bishop_resized', 'bishop_resized', 'pawn_resized', 'rook-resize', 'bishop_resized', 'pawn_resized', 'pawn_resized', 'knight-resize', 'pawn_resized']\n",
      "\n",
      "ğŸ“Š ÎœÎ­ÏƒÎ· Î‘ÎºÏÎ¯Î²ÎµÎ¹Î± Î‘Î½Î¬ÎºÏ„Î·ÏƒÎ·Ï‚ (Top-10): 0.25\n"
     ]
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
